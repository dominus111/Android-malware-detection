import pandas as pd
import numpy as np
from extractor import *
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB

#PREPROCESS THE DATA
dataset = PreProcess()

data = pd.read_csv('data.csv')

feature_names = data.drop(['CLASS', 'NAME'], axis=1).columns


X = data[feature_names]
X = np.asarray(X)
y = data['CLASS']
y = np.asarray(y)

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)


param_grid = {'C': [1e4],
              'gamma': [0.005], }
svclassifier = GridSearchCV(
    SVC(kernel='rbf', class_weight='balanced'), param_grid
)

# CREATE A FIGURE OF THE TOP 20 FEATURES WITH HIGHEST WEIGHT, BOTH FOR BENIGN AND MALICIOUS
def feature_plot(classifier, feature_names, top_features=20):
 coef = classifier.coef_.ravel()
 top_positive_coefficients = np.argsort(coef)[-top_features:]
 top_negative_coefficients = np.argsort(coef)[:top_features]
 top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])
 plt.figure(figsize=(18, 7))
 colors = ['green' if c < 0 else 'blue' for c in coef[top_coefficients]]
 plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)
 feature_names = np.array(feature_names)
 plt.xticks(np.arange(1 + 2 * top_features), feature_names[top_coefficients], rotation=45, ha='right')
 plt.show()


# TRAIN THE MODELS
#svclassifier = SVC(kernel='linear')
svclassifier.fit(X_train, y_train)
randomforest = RandomForestClassifier(n_estimators=200).fit(X_train,y_train)
LR = GaussianNB().fit(X_train,y_train)

#feature_plot(svclassifier,feature_names)
print('SVM')
y_pred = svclassifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))


print('Random Forest')
predictionforest = randomforest.predict(X_test)
print(confusion_matrix(y_test,predictionforest))
print(classification_report(y_test,predictionforest))

print('Naive Bayes')
predictions =LR.predict(X_test)
print(confusion_matrix(y_test,predictions))
print(classification_report(y_test,predictions))
